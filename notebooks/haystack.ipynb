{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to whale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(dataset))\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(item['content']) for item in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"lengths\": lengths}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scrapeWhales import *\n",
    "data = get_data(\"https://en.wikipedia.org/wiki/Whale\")\n",
    "myLengths = [len(cont) for cont in sum(data.values(), [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.DataFrame({\"myLengths\": myLengths}).describe()\n",
    "pd.concat([df, mydf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Whale'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scrapeWhales import *\n",
    "import numpy as np\n",
    "url = \"https://en.wikipedia.org/wiki/Whale\" \n",
    "data = get_data(url)\n",
    "data = [ [(heading, content) for content in contents] for heading, contents in data.items()]\n",
    "data = sum(data, [])\n",
    "docs = [Document(content=txt, meta={'url': url, 'title':heading}) for heading, txt in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs), docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".envargs\")\n",
    "#os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder\n",
    "from haystack.utils import Secret\n",
    "doc_embedder = OpenAIDocumentEmbedder(api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import OpenAITextEmbedder\n",
    "\n",
    "# text_embedder = OpenAITextEmbedder(api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))\n",
    "text_embedder = OpenAITextEmbedder(api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))\n",
    "# text_embedder = OpenAITextEmbedder(api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import OpenAIGenerator\n",
    "generator = OpenAIGenerator(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "# Add components to your pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Now, connect the components to each other\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Are whale arteries larrge enough for a baby to crawl through?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedder.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "text_to_embed = \"I love pizza!\"\n",
    "\n",
    "print(\"Creating Embedded\")\n",
    "text_embedder = SentenceTransformersTextEmbedder()\n",
    "print(\"Warming up embedded\")\n",
    "text_embedder.warm_up()\n",
    "\n",
    "print(\"running embedded\")\n",
    "print(text_embedder.run(text_to_embed))\n",
    "\n",
    "# {'embedding': [-0.07804739475250244, 0.1498992145061493,, ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import OpenAITextEmbedder\n",
    "\n",
    "text_to_embed = \"I love pizza!\"\n",
    "\n",
    "text_embedder = OpenAITextEmbedder(api_key=Secret.from_token(os.getenv(\"OPENAI_API_KEY\")))\n",
    "\n",
    "print(text_embedder.run(text_to_embed))\n",
    "\n",
    "# {'embedding': [0.017020374536514282, -0.023255806416273117, ...],\n",
    "# 'meta': {'model': 'text-embedding-ada-002-v2',\n",
    "#              'usage': {'prompt_tokens': 4, 'total_tokens': 4}}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
